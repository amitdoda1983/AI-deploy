{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee6de320",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c637a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98843f4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap-south-1\n"
     ]
    }
   ],
   "source": [
    "print (region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ed25227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::288564358955:role/service-role/AmazonSageMaker-ExecutionRole-20220315T171898\n"
     ]
    }
   ],
   "source": [
    "print (role)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8c544a",
   "metadata": {},
   "source": [
    "Configuring the bucket for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9d34d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = sagemaker.Session().default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a27280df",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket_path = \"https://s3-{}.amazonaws.com/{}\".format(region, bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "194c8dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::nbclient==0.5.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib==3.3.4=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::qdarkstyle==2.8.1=pyhd8ed1ab_2\n",
      "  - conda-forge/linux-64::scikit-image==0.16.2=py36hb3f55d8_0\n",
      "  - conda-forge/noarch::python-language-server==0.36.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::widgetsnbextension==3.5.1=py36h5fab9bb_4\n",
      "  - conda-forge/noarch::flake8==3.8.4=py_0\n",
      "  - conda-forge/noarch::ipywidgets==7.6.3=pyhd3deb0d_0\n",
      "  - conda-forge/noarch::typing-extensions==3.7.4.3=0\n",
      "  - conda-forge/noarch::path.py==12.5.0=0\n",
      "  - conda-forge/noarch::dask==2021.2.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbformat==5.1.2=pyhd8ed1ab_1\n",
      "  - conda-forge/linux-64::path==15.1.2=py36h5fab9bb_0\n",
      "  - conda-forge/linux-64::nbconvert==6.0.7=py36h5fab9bb_3\n",
      "  - conda-forge/linux-64::distributed==2021.2.0=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::anaconda-client==1.7.2=py_0\n",
      "  - conda-forge/noarch::aioitertools==0.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::matplotlib-base==3.3.4=py36hd391965_0\n",
      "  - conda-forge/linux-64::pluggy==0.13.1=py36h5fab9bb_4\n",
      "  - conda-forge/noarch::black==20.8b1=py_1\n",
      "  - conda-forge/linux-64::blaze==0.11.3=py36_0\n",
      "  - conda-forge/noarch::pyls-spyder==0.3.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::odo==0.5.1=py_1\n",
      "  - conda-forge/linux-64::keyring==22.0.1=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::anaconda-project==0.9.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::importlib_metadata==3.7.0=hd8ed1ab_0\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py36h5fab9bb_6\n",
      "  - conda-forge/noarch::jupyterlab_server==2.3.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::seaborn-base==0.11.1=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::imageio==2.9.0=py_0\n",
      "  - conda-forge/noarch::numpydoc==1.1.0=py_1\n",
      "  - conda-forge/linux-64::yarl==1.6.3=py36h8f6f2f9_1\n",
      "  - conda-forge/noarch::jsonschema==3.2.0=py_2\n",
      "  - conda-forge/noarch::flask==1.1.2=pyh9f0ad1d_0\n",
      "  - conda-forge/noarch::seaborn==0.11.1=hd8ed1ab_1\n",
      "  - conda-forge/noarch::helpdev==0.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::nb_conda==2.2.1=py36h5fab9bb_4\n",
      "  - conda-forge/noarch::nbclassic==0.2.6=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinx==3.5.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::jupyterlab_launcher==0.13.1=py_2\n",
      "  - conda-forge/linux-64::spyder==4.2.0=py36h5fab9bb_0\n",
      "  - conda-forge/linux-64::importlib-metadata==3.7.0=py36h5fab9bb_0\n",
      "  - conda-forge/linux-64::pytest==6.2.2=py36h5fab9bb_0\n",
      "  - conda-forge/noarch::pyls-black==0.4.6=pyh9f0ad1d_0\n",
      "done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.8.4\n",
      "  latest version: 4.11.0\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /home/ec2-user/anaconda3/envs/python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - xgboost==0.90\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    _py-xgboost-mutex-2.0      |            cpu_0           8 KB  conda-forge\n",
      "    anyio-3.3.2                |   py36h5fab9bb_0         147 KB  conda-forge\n",
      "    astroid-2.7.3              |   py36h5fab9bb_0         330 KB  conda-forge\n",
      "    bokeh-2.3.3                |   py36h5fab9bb_0         8.3 MB  conda-forge\n",
      "    charset-normalizer-2.0.12  |     pyhd8ed1ab_0          35 KB  conda-forge\n",
      "    colorama-0.4.4             |     pyh9f0ad1d_0          18 KB  conda-forge\n",
      "    dataclasses-0.8            |     pyh787bdff_2          22 KB  conda-forge\n",
      "    docutils-0.16              |   py36h5fab9bb_3         738 KB  conda-forge\n",
      "    flask-cors-3.0.10          |     pyhd8ed1ab_0          15 KB  conda-forge\n",
      "    fsspec-2022.2.0            |     pyhd8ed1ab_0          92 KB  conda-forge\n",
      "    jupyter_console-5.2.0      |           py36_1          34 KB  conda-forge\n",
      "    jupyter_server-1.13.2      |     pyhd8ed1ab_0         263 KB  conda-forge\n",
      "    libxgboost-0.90            |       he1b5a44_4         2.4 MB  conda-forge\n",
      "    notebook-6.3.0             |   py36h5fab9bb_0         6.3 MB  conda-forge\n",
      "    pillow-8.2.0               |   py36ha6010c0_1         688 KB  conda-forge\n",
      "    platformdirs-2.5.1         |     pyhd8ed1ab_0          15 KB  conda-forge\n",
      "    py-xgboost-0.90            |           py36_4          73 KB  conda-forge\n",
      "    pylint-2.10.2              |     pyhd8ed1ab_0         255 KB  conda-forge\n",
      "    typing_extensions-3.7.4.3  |             py_0          25 KB  conda-forge\n",
      "    websocket-client-1.3.1     |     pyhd8ed1ab_0          41 KB  conda-forge\n",
      "    werkzeug-2.0.2             |     pyhd8ed1ab_0         221 KB  conda-forge\n",
      "    xgboost-0.90               |   py36he1b5a44_4          11 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        20.0 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  _py-xgboost-mutex  conda-forge/linux-64::_py-xgboost-mutex-2.0-cpu_0\n",
      "  anyio              conda-forge/linux-64::anyio-3.3.2-py36h5fab9bb_0\n",
      "  astroid            conda-forge/linux-64::astroid-2.7.3-py36h5fab9bb_0\n",
      "  babel              conda-forge/noarch::babel-2.9.1-pyh44b312d_0\n",
      "  bleach             conda-forge/noarch::bleach-4.1.0-pyhd8ed1ab_0\n",
      "  bokeh              conda-forge/linux-64::bokeh-2.3.3-py36h5fab9bb_0\n",
      "  charset-normalizer conda-forge/noarch::charset-normalizer-2.0.12-pyhd8ed1ab_0\n",
      "  colorama           conda-forge/noarch::colorama-0.4.4-pyh9f0ad1d_0\n",
      "  dask-core          conda-forge/noarch::dask-core-2021.2.0-pyhd8ed1ab_0\n",
      "  dataclasses        conda-forge/noarch::dataclasses-0.8-pyh787bdff_2\n",
      "  docutils           conda-forge/linux-64::docutils-0.16-py36h5fab9bb_3\n",
      "  flask-cors         conda-forge/noarch::flask-cors-3.0.10-pyhd8ed1ab_0\n",
      "  fsspec             conda-forge/noarch::fsspec-2022.2.0-pyhd8ed1ab_0\n",
      "  jupyter_console    conda-forge/linux-64::jupyter_console-5.2.0-py36_1\n",
      "  jupyter_server     conda-forge/noarch::jupyter_server-1.13.2-pyhd8ed1ab_0\n",
      "  libxgboost         conda-forge/linux-64::libxgboost-0.90-he1b5a44_4\n",
      "  nest-asyncio       conda-forge/noarch::nest-asyncio-1.5.4-pyhd8ed1ab_0\n",
      "  notebook           conda-forge/linux-64::notebook-6.3.0-py36h5fab9bb_0\n",
      "  openjpeg           conda-forge/linux-64::openjpeg-2.4.0-hb52868f_1\n",
      "  packaging          conda-forge/noarch::packaging-21.3-pyhd8ed1ab_0\n",
      "  pillow             conda-forge/linux-64::pillow-8.2.0-py36ha6010c0_1\n",
      "  platformdirs       conda-forge/noarch::platformdirs-2.5.1-pyhd8ed1ab_0\n",
      "  py-xgboost         conda-forge/linux-64::py-xgboost-0.90-py36_4\n",
      "  pylint             conda-forge/noarch::pylint-2.10.2-pyhd8ed1ab_0\n",
      "  requests           conda-forge/noarch::requests-2.27.1-pyhd8ed1ab_0\n",
      "  send2trash         conda-forge/noarch::send2trash-1.8.0-pyhd8ed1ab_0\n",
      "  typing_extensions  conda-forge/noarch::typing_extensions-3.7.4.3-py_0\n",
      "  urllib3            conda-forge/noarch::urllib3-1.26.8-pyhd8ed1ab_1\n",
      "  websocket-client   conda-forge/noarch::websocket-client-1.3.1-pyhd8ed1ab_0\n",
      "  werkzeug           conda-forge/noarch::werkzeug-2.0.2-pyhd8ed1ab_0\n",
      "  xgboost            conda-forge/linux-64::xgboost-0.90-py36he1b5a44_4\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "jupyter_server-1.13. | 263 KB    | ##################################### | 100% \n",
      "typing_extensions-3. | 25 KB     | ##################################### | 100% \n",
      "pillow-8.2.0         | 688 KB    | ##################################### | 100% \n",
      "libxgboost-0.90      | 2.4 MB    | ##################################### | 100% \n",
      "websocket-client-1.3 | 41 KB     | ##################################### | 100% \n",
      "_py-xgboost-mutex-2. | 8 KB      | ##################################### | 100% \n",
      "py-xgboost-0.90      | 73 KB     | ##################################### | 100% \n",
      "fsspec-2022.2.0      | 92 KB     | ##################################### | 100% \n",
      "dataclasses-0.8      | 22 KB     | ##################################### | 100% \n",
      "pylint-2.10.2        | 255 KB    | ##################################### | 100% \n",
      "notebook-6.3.0       | 6.3 MB    | ##################################### | 100% \n",
      "jupyter_console-5.2. | 34 KB     | ##################################### | 100% \n",
      "bokeh-2.3.3          | 8.3 MB    | ##################################### | 100% \n",
      "xgboost-0.90         | 11 KB     | ##################################### | 100% \n",
      "colorama-0.4.4       | 18 KB     | ##################################### | 100% \n",
      "flask-cors-3.0.10    | 15 KB     | ##################################### | 100% \n",
      "platformdirs-2.5.1   | 15 KB     | ##################################### | 100% \n",
      "charset-normalizer-2 | 35 KB     | ##################################### | 100% \n",
      "anyio-3.3.2          | 147 KB    | ##################################### | 100% \n",
      "astroid-2.7.3        | 330 KB    | ##################################### | 100% \n",
      "docutils-0.16        | 738 KB    | ##################################### | 100% \n",
      "werkzeug-2.0.2       | 221 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install -y -c conda-forge xgboost==0.90"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a5f0e2",
   "metadata": {},
   "source": [
    "Name of the model file that we have uploaded on AWS cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d8882c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_filename = 'DEMO-local-xgboost-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0783af95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/base.py:315: UserWarning: Trying to unpickle estimator LabelEncoder from version 1.0.2 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import xgboost\n",
    "\n",
    "mymodel = joblib.load(model_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9866a075",
   "metadata": {},
   "source": [
    "Upload some test records on AWS cloud and evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b299a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.4 3.  4.5 1.5]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.  3.  4.8 1.8]\n",
      " [5.1 3.3 1.7 0.5]]\n"
     ]
    }
   ],
   "source": [
    "#import json\n",
    "import numpy as np\n",
    "\n",
    "file_name = (\n",
    "    \"test_point.csv\"  # customize to your test file, will be 'mnist.single.test' if use data above\n",
    ")\n",
    "\n",
    "with open(file_name, \"r\") as f:\n",
    "    mypayload = np.loadtxt(f, delimiter=\",\")\n",
    "    \n",
    "print(mypayload)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1649276",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 2, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mymodel.predict(mypayload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4695013d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel._Booster.save_model(model_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "309f508f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEMO-local-xgboost-model\r\n"
     ]
    }
   ],
   "source": [
    "!tar czvf model.tar.gz $model_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4641e",
   "metadata": {},
   "source": [
    "Pushing the model to S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "571ae71a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sagemaker/my-xgboost-byo/DEMO-local-xgboost-model/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "#### prefix in S3\n",
    "prefix = \"sagemaker/my-xgboost-byo\"\n",
    "\n",
    "fObj = open(\"model.tar.gz\", \"rb\")\n",
    "key = os.path.join(prefix, model_filename, \"model.tar.gz\")\n",
    "print(key)\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(key).upload_fileobj(fObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8873331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "#### Get the built-in xgboost container image in Sagemaker to host our model\n",
    "container = get_image_uri(boto3.Session().region_name, \"xgboost\", \"0.90-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6d5db029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://s3-ap-south-1.amazonaws.com/sagemaker-ap-south-1-288564358955/sagemaker/my-xgboost-byo/DEMO-local-xgboost-model/model.tar.gz\n",
      "arn:aws:sagemaker:ap-south-1:288564358955:model/demo-local-xgboost-model2022-03-15-12-10-00\n",
      "CPU times: user 76.3 ms, sys: 3.18 ms, total: 79.5 ms\n",
      "Wall time: 414 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "model_name = model_filename + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "model_url = \"https://s3-{}.amazonaws.com/{}/{}\".format(region, bucket, key)\n",
    "\n",
    "sm_client = boto3.client(\"sagemaker\")\n",
    "\n",
    "print(model_url)\n",
    "\n",
    "primary_container = {\n",
    "    \"Image\": container,\n",
    "    \"ModelDataUrl\": model_url,\n",
    "}\n",
    "\n",
    "create_model_response2 = sm_client.create_model(\n",
    "    ModelName=model_name, ExecutionRoleArn=role, PrimaryContainer=primary_container\n",
    ")\n",
    "\n",
    "print(create_model_response2[\"ModelArn\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c50034",
   "metadata": {},
   "source": [
    "Creating the model endpoint on AWS sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e40aaa4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-XGBoostEndpointConfig-2022-03-15-12-10-37\n",
      "Endpoint Config Arn: arn:aws:sagemaker:ap-south-1:288564358955:endpoint-config/my-xgboostendpointconfig-2022-03-15-12-10-37\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "\n",
    "endpoint_config_name = \"my-XGBoostEndpointConfig-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "print(endpoint_config_name)\n",
    "\n",
    "create_endpoint_config_response = sm_client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "            \"InstanceType\": \"ml.m4.xlarge\",\n",
    "            \"InitialInstanceCount\": 1,\n",
    "            \"InitialVariantWeight\": 1,\n",
    "            \"ModelName\": model_name,\n",
    "            \"VariantName\": \"AllTraffic\",\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(\"Endpoint Config Arn: \" + create_endpoint_config_response[\"EndpointConfigArn\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8266d159",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my-XGBoostEndpoint-2022-03-15-12-11-49\n",
      "arn:aws:sagemaker:ap-south-1:288564358955:endpoint/my-xgboostendpoint-2022-03-15-12-11-49\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: Creating\n",
      "Status: InService\n",
      "Arn: arn:aws:sagemaker:ap-south-1:288564358955:endpoint/my-xgboostendpoint-2022-03-15-12-11-49\n",
      "Status: InService\n",
      "CPU times: user 61.5 ms, sys: 0 ns, total: 61.5 ms\n",
      "Wall time: 3min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "endpoint_name = \"my-XGBoostEndpoint-\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "print(endpoint_name)\n",
    "create_endpoint_response = sm_client.create_endpoint(\n",
    "    EndpointName=endpoint_name, EndpointConfigName=endpoint_config_name\n",
    ")\n",
    "print(create_endpoint_response[\"EndpointArn\"])\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "print(\"Status: \" + status)\n",
    "\n",
    "while status == \"Creating\":\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "    print(\"Status: \" + status)\n",
    "\n",
    "print(\"Arn: \" + resp[\"EndpointArn\"])\n",
    "print(\"Status: \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ed89568b",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_client = boto3.client(\"runtime.sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "456e9827",
   "metadata": {},
   "source": [
    "Evaluating the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96088ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Payload :\n",
      "\n",
      "5.400000000000000355e+00,3.000000000000000000e+00,4.500000000000000000e+00,1.500000000000000000e+00\n",
      "5.599999999999999645e+00,3.000000000000000000e+00,4.099999999999999645e+00,1.300000000000000044e+00\n",
      "6.299999999999999822e+00,2.799999999999999822e+00,5.099999999999999645e+00,1.500000000000000000e+00\n",
      "6.000000000000000000e+00,3.000000000000000000e+00,4.799999999999999822e+00,1.800000000000000044e+00\n",
      "5.099999999999999645e+00,3.299999999999999822e+00,1.699999999999999956e+00,5.000000000000000000e-01\n",
      "\n",
      "Results :\n",
      "\n",
      "\n",
      "\n",
      "Predicted Class Probabilities: [0.056180261075496674, 0.887361466884613, 0.056458208709955215],[0.056180261075496674, 0.887361466884613, 0.056458208709955215],[0.08053058385848999, 0.8385403752326965, 0.08092901110649109],[0.12150664627552032, 0.27632802724838257, 0.6021653413772583],[0.8827555775642395, 0.0601295568048954, 0.05711490288376808].\n",
      "CPU times: user 10.6 ms, sys: 3.34 ms, total: 14 ms\n",
      "Wall time: 144 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "\n",
    "file_name = (\n",
    "    \"test_point.csv\"  # customize to your test file, will be 'mnist.single.test' if use data above\n",
    ")\n",
    "\n",
    "with open(file_name, \"r\") as f:\n",
    "    payload = f.read().strip()\n",
    "    \n",
    "    \n",
    "print(\"Payload :\\n\")\n",
    "\n",
    "print(payload)\n",
    "print()\n",
    "\n",
    "response = runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name, ContentType=\"text/csv\", Body=payload\n",
    ")\n",
    "\n",
    "##print(response)\n",
    "\n",
    "print(\"Results :\\n\")\n",
    "print()\n",
    "\n",
    "result = response[\"Body\"].read().decode(\"ascii\")\n",
    "\n",
    "# Unpack response\n",
    "print(\"\\nPredicted Class Probabilities: {}.\".format(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d212a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
